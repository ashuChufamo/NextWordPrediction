{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Packages"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:32:18.446899Z","iopub.status.busy":"2023-11-19T19:32:18.446099Z","iopub.status.idle":"2023-11-19T19:32:18.459585Z","shell.execute_reply":"2023-11-19T19:32:18.458391Z","shell.execute_reply.started":"2023-11-19T19:32:18.446850Z"},"trusted":true},"outputs":[],"source":["from collections import Counter\n","import random"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-19T19:32:26.608050Z","iopub.status.busy":"2023-11-19T19:32:26.606406Z","iopub.status.idle":"2023-11-19T19:32:32.408454Z","shell.execute_reply":"2023-11-19T19:32:32.407240Z","shell.execute_reply.started":"2023-11-19T19:32:26.607972Z"},"trusted":true},"outputs":[],"source":["dataset_path = \"dummy_amharic.txt\"\n","with open(dataset_path, \"r\", encoding=\"utf8\") as file:\n","    corpus_text = file.read()"]},{"cell_type":"markdown","metadata":{},"source":["## Create n-grams for n=1, 2, 3, 4.\n","\n","Since the dataset is too large, we will read the first 10,000,000 words to create the n-grams for demonstration."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:32:33.738564Z","iopub.status.busy":"2023-11-19T19:32:33.738203Z","iopub.status.idle":"2023-11-19T19:32:33.744581Z","shell.execute_reply":"2023-11-19T19:32:33.743213Z","shell.execute_reply.started":"2023-11-19T19:32:33.738535Z"},"trusted":true},"outputs":[],"source":["def create_ngrams(text, n):\n","    words = text[:10000000]\n","    words = words.split()\n","    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n","    return ngrams"]},{"cell_type":"markdown","metadata":{},"source":["### N = 1 (Unigrams)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:32:48.260522Z","iopub.status.busy":"2023-11-19T19:32:48.260116Z","iopub.status.idle":"2023-11-19T19:32:49.326181Z","shell.execute_reply":"2023-11-19T19:32:49.325100Z","shell.execute_reply.started":"2023-11-19T19:32:48.260491Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["N-grams for n=1: \n","ምን\n","መሰላችሁ?\n","(አንባቢያን)\n","ኢትዮጵያ\n","በተደጋጋሚ\n"]}],"source":["unigrams = create_ngrams(corpus_text, 1)\n","\n","print(\"N-grams for n=1: \")\n","for i in range(5):\n","    print(unigrams[i][0])"]},{"cell_type":"markdown","metadata":{},"source":["## N = 2 (Bigrams)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:32:51.497359Z","iopub.status.busy":"2023-11-19T19:32:51.496597Z","iopub.status.idle":"2023-11-19T19:32:52.502315Z","shell.execute_reply":"2023-11-19T19:32:52.500424Z","shell.execute_reply.started":"2023-11-19T19:32:51.497320Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["N-grams for n=2: \n","('ምን', 'መሰላችሁ?')\n","('መሰላችሁ?', '(አንባቢያን)')\n","('(አንባቢያን)', 'ኢትዮጵያ')\n","('ኢትዮጵያ', 'በተደጋጋሚ')\n","('በተደጋጋሚ', 'ጥሪው')\n"]}],"source":["bigrams = create_ngrams(corpus_text, 2)\n","\n","print(\"N-grams for n=2: \")\n","for i in range(5):\n","    print(bigrams[i])"]},{"cell_type":"markdown","metadata":{},"source":["## N = 3 (Trigrams)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:32:54.897574Z","iopub.status.busy":"2023-11-19T19:32:54.897039Z","iopub.status.idle":"2023-11-19T19:32:55.934146Z","shell.execute_reply":"2023-11-19T19:32:55.932716Z","shell.execute_reply.started":"2023-11-19T19:32:54.897523Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["N-grams for n=3: \n","('ምን', 'መሰላችሁ?', '(አንባቢያን)')\n","('መሰላችሁ?', '(አንባቢያን)', 'ኢትዮጵያ')\n","('(አንባቢያን)', 'ኢትዮጵያ', 'በተደጋጋሚ')\n","('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው')\n","('በተደጋጋሚ', 'ጥሪው', 'ደርሷት')\n"]}],"source":["trigrams = create_ngrams(corpus_text, 3)\n","\n","print(\"N-grams for n=3: \")\n","for i in range(5):\n","    print(trigrams[i])"]},{"cell_type":"markdown","metadata":{},"source":["## N = 4 (Quadgrams)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T20:02:13.639560Z","iopub.status.busy":"2023-11-19T20:02:13.639152Z","iopub.status.idle":"2023-11-19T20:02:14.784248Z","shell.execute_reply":"2023-11-19T20:02:14.782980Z","shell.execute_reply.started":"2023-11-19T20:02:13.639529Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["N-grams for n=4: \n","('ምን', 'መሰላችሁ?', '(አንባቢያን)', 'ኢትዮጵያ')\n","('መሰላችሁ?', '(አንባቢያን)', 'ኢትዮጵያ', 'በተደጋጋሚ')\n","('(አንባቢያን)', 'ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው')\n","('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው', 'ደርሷት')\n","('በተደጋጋሚ', 'ጥሪው', 'ደርሷት', 'ልትታደመው')\n"]}],"source":["quadgrams = create_ngrams(corpus_text, 4)\n","\n","print(\"N-grams for n=4: \")\n","for i in range(5):\n","    print(quadgrams[i])"]},{"cell_type":"markdown","metadata":{},"source":["### Probabilities of n-grams and the top 10 most likely n-grams for all n. "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:11.102045Z","iopub.status.busy":"2023-11-19T19:33:11.100904Z","iopub.status.idle":"2023-11-19T19:33:14.654377Z","shell.execute_reply":"2023-11-19T19:33:14.653313Z","shell.execute_reply.started":"2023-11-19T19:33:11.101990Z"},"trusted":true},"outputs":[],"source":["# Precalculate the count of N-grams\n","unigram_counts = Counter(unigrams)\n","bigram_counts = Counter(bigrams)\n","trigram_counts = Counter(trigrams)\n","quadgram_counts = Counter(quadgrams)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:15.794917Z","iopub.status.busy":"2023-11-19T19:33:15.794539Z","iopub.status.idle":"2023-11-19T19:33:15.802281Z","shell.execute_reply":"2023-11-19T19:33:15.801202Z","shell.execute_reply.started":"2023-11-19T19:33:15.794885Z"},"trusted":true},"outputs":[],"source":["# A function that calculates the n-gram probabilities\n","def calculate_unigram_probabilities(ngrams):\n","    total_ngrams = len(ngrams)\n","    probabilities = {ngram: count/total_ngrams for ngram, count in unigram_counts.items()}\n","    return probabilities\n","    \n","def calculate_bigram_probabilities(ngrams):\n","    probabilities = {ngram: bigram_counts[ngram] / unigram_counts[(ngram[0],)] for ngram in ngrams}\n","    return probabilities\n","        \n","def calculate_trigram_probabilities(ngrams):\n","    probabilities = {ngram: trigram_counts[ngram] / bigram_counts[ngram[:-1]] for ngram in ngrams}\n","    return probabilities\n","\n","def calculate_quadgram_probabilities(ngrams):\n","    probabilities = {ngram: quadgram_counts[ngram] / trigram_counts[ngram[:-1]] for ngram in ngrams}\n","    return probabilities"]},{"cell_type":"markdown","metadata":{},"source":["### Unigram Probabilities"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:18.953638Z","iopub.status.busy":"2023-11-19T19:33:18.953218Z","iopub.status.idle":"2023-11-19T19:33:19.349905Z","shell.execute_reply":"2023-11-19T19:33:19.348465Z","shell.execute_reply.started":"2023-11-19T19:33:18.953602Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The top 10 Unigrams are: \n","\n","ላይ ==> 0.008816936727776477\n","\n","ነው፡፡ ==> 0.007893395073803164\n","\n","ነው ==> 0.006644903578617018\n","\n","ግን ==> 0.004631604151234221\n","\n","ወደ ==> 0.00455784908859052\n","\n","ውስጥ ==> 0.004460577919016941\n","\n","እና ==> 0.004305585396070031\n","\n","ነገር ==> 0.003673857250817452\n","\n","ጋር ==> 0.003634841891592885\n","\n","ጊዜ ==> 0.00308648903454623\n"]}],"source":["# Calculate probabilities\n","unigram_probabilities = calculate_unigram_probabilities(unigrams)\n","\n","top_unigrams = dict(sorted(unigram_probabilities.items(), key=lambda x: x[1], reverse=True)[:10])\n","\n","print(\"The top 10 Unigrams are: \")\n","for top, prob in top_unigrams.items():\n","    print(f'\\n{top[0]} ==> {prob}')"]},{"cell_type":"markdown","metadata":{},"source":["### Bigram Probabilities"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:24.604285Z","iopub.status.busy":"2023-11-19T19:33:24.603912Z","iopub.status.idle":"2023-11-19T19:33:28.633793Z","shell.execute_reply":"2023-11-19T19:33:28.632752Z","shell.execute_reply.started":"2023-11-19T19:33:24.604255Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The top 10 Bigrams are: \n","\n","('ልትታደመው', 'ያልቻለችው') ==> 1.0\n","\n","('ለ19ኛ', 'ጊዜ') ==> 1.0\n","\n","('ባረረ', 'ልክ') ==> 1.0\n","\n","('ልትታደም', 'ሁለት') ==> 1.0\n","\n","('ላከች፡፡6ኛው', 'ቢግ') ==> 1.0\n","\n","('የሚገጥሟቸውን', 'የተለያዩ') ==> 1.0\n","\n","('በትእግስትና', 'በጥበብ') ==> 1.0\n","\n","('ለ91', 'ቀናት') ==> 1.0\n","\n","('እንደሚሸለሙም', 'ሲናገር') ==> 1.0\n","\n","('ብታሰልፍም', 'ዳኒ') ==> 1.0\n"]}],"source":["# Calculate probabilities\n","bigram_probabilities = calculate_bigram_probabilities(bigrams)\n","\n","top_bigrams = dict(sorted(bigram_probabilities.items(), key=lambda x: x[1], reverse=True)[:10])\n","\n","print(\"The top 10 Bigrams are: \")\n","for top, prob in top_bigrams.items():\n","    print(f'\\n{top} ==> {prob}')"]},{"cell_type":"markdown","metadata":{},"source":["### Trigram Probabilities"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:28.635837Z","iopub.status.busy":"2023-11-19T19:33:28.635492Z","iopub.status.idle":"2023-11-19T19:33:32.274933Z","shell.execute_reply":"2023-11-19T19:33:32.273879Z","shell.execute_reply.started":"2023-11-19T19:33:28.635807Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The top 10 Trigrams are: \n","\n","('መሰላችሁ?', '(አንባቢያን)', 'ኢትዮጵያ') ==> 1.0\n","\n","('(አንባቢያን)', 'ኢትዮጵያ', 'በተደጋጋሚ') ==> 1.0\n","\n","('በተደጋጋሚ', 'ጥሪው', 'ደርሷት') ==> 1.0\n","\n","('ጥሪው', 'ደርሷት', 'ልትታደመው') ==> 1.0\n","\n","('ደርሷት', 'ልትታደመው', 'ያልቻለችው') ==> 1.0\n","\n","('ልትታደመው', 'ያልቻለችው', 'የአለም') ==> 1.0\n","\n","('ያልቻለችው', 'የአለም', 'የእግር') ==> 1.0\n","\n","('የአለም', 'የእግር', 'ኳስ') ==> 1.0\n","\n","('ኳስ', 'ዋ', 'ለ19ኛ') ==> 1.0\n","\n","('ዋ', 'ለ19ኛ', 'ጊዜ') ==> 1.0\n"]}],"source":["# Calculate probabilities\n","trigram_probabilities = calculate_trigram_probabilities(trigrams)\n","\n","top_trigrams = dict(sorted(trigram_probabilities.items(), key=lambda x: x[1], reverse=True)[:10])\n","\n","print(\"The top 10 Trigrams are: \")\n","for top, prob in top_trigrams.items():\n","    print(f'\\n{top} ==> {prob}')"]},{"cell_type":"markdown","metadata":{},"source":["### Quadgram Probabilities"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:35.587981Z","iopub.status.busy":"2023-11-19T19:33:35.587481Z","iopub.status.idle":"2023-11-19T19:33:38.860270Z","shell.execute_reply":"2023-11-19T19:33:38.859060Z","shell.execute_reply.started":"2023-11-19T19:33:35.587865Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The top 10 Quadgrams are: \n","\n","('ምን', 'መሰላችሁ?', '(አንባቢያን)', 'ኢትዮጵያ') ==> 1.0\n","\n","('መሰላችሁ?', '(አንባቢያን)', 'ኢትዮጵያ', 'በተደጋጋሚ') ==> 1.0\n","\n","('(አንባቢያን)', 'ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው') ==> 1.0\n","\n","('ኢትዮጵያ', 'በተደጋጋሚ', 'ጥሪው', 'ደርሷት') ==> 1.0\n","\n","('በተደጋጋሚ', 'ጥሪው', 'ደርሷት', 'ልትታደመው') ==> 1.0\n","\n","('ጥሪው', 'ደርሷት', 'ልትታደመው', 'ያልቻለችው') ==> 1.0\n","\n","('ደርሷት', 'ልትታደመው', 'ያልቻለችው', 'የአለም') ==> 1.0\n","\n","('ልትታደመው', 'ያልቻለችው', 'የአለም', 'የእግር') ==> 1.0\n","\n","('ያልቻለችው', 'የአለም', 'የእግር', 'ኳስ') ==> 1.0\n","\n","('የእግር', 'ኳስ', 'ዋ', 'ለ19ኛ') ==> 1.0\n"]}],"source":["# Calculate probabilities\n","quadgram_probabilities = calculate_quadgram_probabilities(quadgrams)\n","\n","top_quadgrams = dict(sorted(quadgram_probabilities.items(), key=lambda x: x[1], reverse=True)[:10])\n","\n","print(\"The top 10 Quadgrams are: \")\n","for top, prob in top_quadgrams.items():\n","    print(f'\\n{top} ==> {prob}')"]},{"cell_type":"markdown","metadata":{},"source":["### Lets take a random sentence and calculate it's probability. \"ኢትዮጵያ ታሪካዊ ሀገር ናት \"?\n","\n","Let's calculate the probability of the sentence using different n-gram models: Unigram, Bigram, Trigram, and Quadgram."]},{"cell_type":"markdown","metadata":{},"source":["#### Unigram Estimation\n","\n","Finding the probability of the sentence using Unigram Estimation"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:41.218009Z","iopub.status.busy":"2023-11-19T19:33:41.217322Z","iopub.status.idle":"2023-11-19T19:33:41.225989Z","shell.execute_reply":"2023-11-19T19:33:41.224876Z","shell.execute_reply.started":"2023-11-19T19:33:41.217962Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Probability of the sentence 'ኢትዮጵያ ታሪካዊ ሀገር ናት': 4.200190248383804e-15\n","\n"]}],"source":["def unigram_probability_estimation(sentence):\n","    # Find probability using the Unigrams\n","    sentence_ngrams = create_ngrams(sentence, 1)\n","    sentence_probability = 1.0\n","    for ngram in sentence_ngrams:\n","        sentence_probability *= unigram_probabilities.get(ngram, 1e-10)  # to avoid division by zero\n","    return sentence_probability\n","\n","sentence = \"ኢትዮጵያ ታሪካዊ ሀገር ናት\"\n","sentence_probability = unigram_probability_estimation(sentence)\n","print(f\"Probability of the sentence '{sentence}': {sentence_probability}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Bigram Estimation\n","\n","Finding the probability of the sentence using Bigram Estimation"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:47.854938Z","iopub.status.busy":"2023-11-19T19:33:47.854524Z","iopub.status.idle":"2023-11-19T19:33:47.862211Z","shell.execute_reply":"2023-11-19T19:33:47.860887Z","shell.execute_reply.started":"2023-11-19T19:33:47.854903Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Probability of the sentence 'ኢትዮጵያ ታሪካዊ ሀገር ናት': 1.9796198140147185e-16\n","\n"]}],"source":["def bigram_probability_estimation(sentence):\n","    # Find probability using the Unigrams\n","    sentence_ngrams = create_ngrams(sentence, 2)\n","    sentence_probability = 1.0\n","    for ngram in sentence_ngrams:\n","        sentence_probability *= bigram_probabilities.get(ngram, 1e-10)  # to avoid division by zero\n","    return sentence_probability\n","\n","sentence = \"ኢትዮጵያ ታሪካዊ ሀገር ናት\"\n","sentence_probability = bigram_probability_estimation(sentence)\n","print(f\"Probability of the sentence '{sentence}': {sentence_probability}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Trigram Estimation\n","\n","Finding the probability of the sentence using Trigram Estimation"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:51.820519Z","iopub.status.busy":"2023-11-19T19:33:51.820144Z","iopub.status.idle":"2023-11-19T19:33:51.828088Z","shell.execute_reply":"2023-11-19T19:33:51.826810Z","shell.execute_reply.started":"2023-11-19T19:33:51.820487Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Probability of ኢትዮጵያ ታሪካዊ ሀገር ናት using Trigram Estimation is: ': 1.0000000000000001e-20\n","\n"]}],"source":["def trigram_probability_estimation(sentence):\n","    # Find probability using the Unigrams\n","    sentence_ngrams = create_ngrams(sentence, 3)\n","    sentence_probability = 1.0\n","    for ngram in sentence_ngrams:\n","        sentence_probability *= trigram_probabilities.get(ngram, 1e-10) # to avoid division by zero\n","    return sentence_probability\n","        \n","sentence = \"ኢትዮጵያ ታሪካዊ ሀገር ናት\"\n","sentence_probability = trigram_probability_estimation(sentence)\n","print(f\"Probability of {sentence} using Trigram Estimation is: ': {sentence_probability}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Quadgram Estimation\n","\n","Finding the probability of the sentence using Quadgram Estimation"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:33:55.269791Z","iopub.status.busy":"2023-11-19T19:33:55.269386Z","iopub.status.idle":"2023-11-19T19:33:55.277027Z","shell.execute_reply":"2023-11-19T19:33:55.275685Z","shell.execute_reply.started":"2023-11-19T19:33:55.269753Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Probability of ኢትዮጵያ ታሪካዊ ሀገር ናት using Quadgram Estimation is: ': 1e-10\n","\n"]}],"source":["def quadgram_probability_estimation(sentence):\n","    # Find probability using the Unigrams\n","    sentence_ngrams = create_ngrams(sentence, 4)\n","    sentence_probability = 1.0\n","    for ngram in sentence_ngrams:\n","        sentence_probability *= quadgram_probabilities.get(ngram, 1e-10)  # to avoid division by zero\n","    return sentence_probability\n","\n","sentence = \"ኢትዮጵያ ታሪካዊ ሀገር ናት\"\n","sentence_probability = quadgram_probability_estimation(sentence)\n","print(f\"Probability of {sentence} using Quadgram Estimation is: ': {sentence_probability}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Finiding the probability of the sentence using the Chain Rule"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:34:06.822852Z","iopub.status.busy":"2023-11-19T19:34:06.822500Z","iopub.status.idle":"2023-11-19T19:34:06.830353Z","shell.execute_reply":"2023-11-19T19:34:06.829122Z","shell.execute_reply.started":"2023-11-19T19:34:06.822822Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Probability of ኢትዮጵያ ታሪካዊ ሀገር ናት using Chain Rule is: ': 5.3445697567900095e-27\n"]}],"source":["def chain_rule_probability_estimation(sentence):\n","\n","    sentence = sentence.split()\n","    # Find probability using the Unigrams\n","    sentence_probability = 1.0\n","    sentence_probability *= unigram_probabilities.get((sentence[0],), 1e-10)\n","    sentence_probability *= bigram_probabilities.get(tuple(sentence[:2]), 1e-10)\n","    sentence_probability *= trigram_probabilities.get(tuple(sentence[:3]), 1e-10)\n","    sentence_probability *= quadgram_probabilities.get(tuple(sentence[:4]), 1e-10)\n","    return sentence_probability\n","\n","\n","sentence = \"ኢትዮጵያ ታሪካዊ ሀገር ናት\"\n","sentence_probability = chain_rule_probability_estimation(sentence)\n","print(f\"Probability of {sentence} using Chain Rule is: ': {sentence_probability}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Lets generate random sentences using n-grams; see what happens as n increases \n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:48:26.871677Z","iopub.status.busy":"2023-11-19T19:48:26.870601Z","iopub.status.idle":"2023-11-19T19:48:26.883073Z","shell.execute_reply":"2023-11-19T19:48:26.880781Z","shell.execute_reply.started":"2023-11-19T19:48:26.871636Z"},"trusted":true},"outputs":[],"source":["def generate_random_sentence_for_unigrams(seed_word, ngram_probabilities, n, reps = 10):\n","    sentence = [*seed_word]\n","    choices = list(ngram_probabilities.keys())\n","    for _ in range(reps):\n","        next_word = random.choice(choices)\n","        sentence.append(next_word[-1])\n","    return \" \".join(sentence)\n","        \n","def generate_random_sentence_for_ngrams(seed_word, ngram_probabilities, n, reps = 10):\n","    sentence = [*seed_word]\n","    for _ in range(reps): \n","        # Get the possible next words based on the n-gram\n","        next_words = [word[-1] for word in ngram_probabilities if word[:-1] == tuple(sentence[-(n-1):])]\n","        if not next_words:\n","            break  # Stop if there are no valid next words\n","\n","        # Probabilistically choose the next word\n","        next_word = random.choice(next_words)\n","        sentence.append(next_word)\n","        \n","    return \" \".join(sentence)\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:36:08.026491Z","iopub.status.busy":"2023-11-19T19:36:08.026116Z","iopub.status.idle":"2023-11-19T19:36:29.312787Z","shell.execute_reply":"2023-11-19T19:36:29.311322Z","shell.execute_reply.started":"2023-11-19T19:36:08.026461Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated random sentence using Unigrams: በአወዛጋቢ የፊልምንና ጠቀየው፡፡ ልውውጦችና ያሰኝ ይታወቃሉ፡፡ግንቦት ኮምፒዩተሮችም ሃዘኑን ነበር?(ይቀጥላል) በተመሳሠብ ያሸነፈችኝ?\n","Generated random sentence using bigrams: ሲገልፁ ኖረዋል። ይህ ባይሆን ድሪንክዬው በቀለም የመሙላት የከንፈር ወዳጅ፣ አንደበተ መልካም አሽከር\n","Generated random sentence using trigrams: የፓርቲውን ውሳኔ በግሌ በጣም ነው የተደሰትኩ ለሙዚቃ ያለው ፍቅር በጣም ይገርማል በፊት ከመጫወት\n","Generated random sentence using quadgrams: ደግሞ ጥሎብኝ ውበት አደንቃለሁ፡፡ ፍሬነገሩ ብቻ አይማርከኝም፡፡ውበት መፍጠርም ውድ ተሰጥዖ ነው፡፡ የተመኘ ሁሉ አያገኘውም፡፡\n"]}],"source":["# Using Unigrams\n","seed_word = random.choice(list(unigram_probabilities.keys()))\n","generated_sentence = generate_random_sentence_for_unigrams(seed_word, unigram_probabilities, 1)\n","print(\"Generated random sentence using Unigrams:\", generated_sentence)\n","\n","# Using Bigrams\n","seed_word = random.choice(list(bigram_probabilities.keys()))\n","generated_sentence = generate_random_sentence_for_ngrams(seed_word, bigram_probabilities, 2)\n","print(\"Generated random sentence using bigrams:\", generated_sentence)\n","\n","\n","# Using Trigrams\n","seed_word = random.choice(list(trigram_probabilities.keys()))\n","generated_sentence = generate_random_sentence_for_ngrams(seed_word, trigram_probabilities, 3)\n","print(\"Generated random sentence using trigrams:\", generated_sentence)\n","\n","# Using Quadgrams\n","seed_word = random.choice(list(quadgram_probabilities.keys()))\n","generated_sentence = generate_random_sentence_for_ngrams(seed_word, quadgram_probabilities, 4)\n","print(\"Generated random sentence using quadgrams:\", generated_sentence)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Explanation\n","\n","As n increases, the model takes more context into account when generating text. \n","\n","<b>1. More Contextual Relevance:</b> With larger n, the generated sentences tend to be more contextually relevant and coherent. This is because the model considers a longer history of words when predicting the next word.\n","\n","<b>2. Computational Complexity: </b> The models became more resource-intensive with larger n.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluating these Language Models Using Intrinsic Evaluation Method\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:36:46.723997Z","iopub.status.busy":"2023-11-19T19:36:46.723634Z","iopub.status.idle":"2023-11-19T19:36:46.734613Z","shell.execute_reply":"2023-11-19T19:36:46.733712Z","shell.execute_reply.started":"2023-11-19T19:36:46.723969Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Perplexity on Test Set using Unigrams: 2.0785114808271317e+20\n","Average Perplexity on Test Set using Bigrams: 1693942611.7401881\n","Average Perplexity on Test Set using Trigrams: 8434326.653017484\n","Average Perplexity on Test Set using Quadgrams: 2154.434690031883\n"]}],"source":["import math\n","\n","def calculate_probability(sentence, ngram_probabilities, n, probability_function):\n","    splitted_sentence = sentence.split()\n","    sentence_ngrams = [tuple(splitted_sentence[i:i+n]) for i in range(len(splitted_sentence)-n+1)]\n","    \n","    # Calculate probability\n","    sentence_probability = probability_function(sentence)\n","    return sentence_probability\n","\n","def evaluate_language_model(test_set, ngram_probabilities, n, probability_function):\n","    N = len(test_set)\n","    total_perplexity = 1\n","    for sentence in test_set:\n","        probability = calculate_probability(sentence, ngram_probabilities, n, probability_function)\n","        total_perplexity *= 1 / probability\n","\n","    total_perplexity = pow(total_perplexity, 1/N)\n","    return total_perplexity\n","\n","# Example usage for bigrams\n","test_set = [\"ኢትዮጵያ በተደጋጋሚ ጥሪው ደርሷት ልትታደመው ያልቻለችው\", \"ኢትዮጵያ ታሪካዊ ሀገር ናት\", \"ተወዳዳሪዎች እያንዳንዳቸው 200 ሺህ\"]\n","\n","intrinsic_evaluation_result = evaluate_language_model(test_set, unigram_probabilities, 1, unigram_probability_estimation)\n","print(f\"Average Perplexity on Test Set using Unigrams: {intrinsic_evaluation_result}\")\n","\n","intrinsic_evaluation_result = evaluate_language_model(test_set, bigram_probabilities, 2, bigram_probability_estimation)\n","print(f\"Average Perplexity on Test Set using Bigrams: {intrinsic_evaluation_result}\")\n","\n","intrinsic_evaluation_result = evaluate_language_model(test_set, trigram_probabilities, 3, trigram_probability_estimation)\n","print(f\"Average Perplexity on Test Set using Trigrams: {intrinsic_evaluation_result}\")\n","\n","intrinsic_evaluation_result = evaluate_language_model(test_set, quadgram_probabilities, 4, quadgram_probability_estimation)\n","print(f\"Average Perplexity on Test Set using Quadgrams: {intrinsic_evaluation_result}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluating these Language Models Using Extrinsic Evaluation Method\n","\n","We chose sentence completion as a task to evaluate these language models\n","\n","We can use the functions that we created before to generate random sentence but for generating the next word for the given initial sentence."]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T20:02:30.882391Z","iopub.status.busy":"2023-11-19T20:02:30.881956Z","iopub.status.idle":"2023-11-19T20:02:52.782241Z","shell.execute_reply":"2023-11-19T20:02:52.780577Z","shell.execute_reply.started":"2023-11-19T20:02:30.882357Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1-gram Completed Sentence: ደቡብ አፍሪካ ለስድስተኛ እንደቀለበት ይታዘዛል፡፡ እንደሚመለከቱ በይዘቱ እያለች፣ በሞኒተሪ ሲጠብቁ፣ ዲናርና አልገጠማችሁም?በህጋዊ በሲቪክ \n","\n","2-gram Completed Sentence: ደቡብ አፍሪካ ለስድስተኛ ጊዜ ለማጣራትና ምዝገባ በአዲሱ ጭማሪ ተደርጐባቸዋል የሚሉት ምንድን ነበር መሰለህ \n","\n","3-gram Completed Sentence: ደቡብ አፍሪካ ለስድስተኛ ጊዜ ካዘጋጀችው ቢግ ብራዘርስ ሶስት ወር አካባቢ ተገቢውን ምክር እየለገስናቸው\n","\n","\n","4-gram Completed Sentence:  ደቡብ አፍሪካ ለስድስተኛ ጊዜ ካዘጋጀችው ቢግ ብራዘርስ የመረረ ውድድር ለሺህ አመታት በተከታታይ ስታዘጋጅ\n"]}],"source":["# Examples\n","initial_sentence = \"ደቡብ አፍሪካ ለስድስተኛ\"\n","initial_sentence = tuple(initial_sentence.split())\n","# Test for all four n-gram models\n","\n","\n","completed_word = generate_random_sentence_for_unigrams(initial_sentence, unigram_probabilities, 1)\n","print(f\"1-gram Completed Sentence: {completed_word} \\n\")\n","\n","completed_word = generate_random_sentence_for_ngrams(initial_sentence, bigram_probabilities, 2)\n","print(f\"2-gram Completed Sentence: {completed_word} \\n\")\n","\n","completed_word = generate_random_sentence_for_ngrams(initial_sentence, trigram_probabilities, 3)\n","print(f\"3-gram Completed Sentence: {completed_word}\")\n","print(\"\\n\")\n","completed_word = generate_random_sentence_for_ngrams(initial_sentence, quadgram_probabilities, 4)\n","print(f\"4-gram Completed Sentence:  {completed_word}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Next Word Prediction"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["def generate_next_words(seed_word, n):\n","    if n == 1:\n","        ngram_probabilities = unigram_probabilities\n","    elif n == 2:\n","        ngram_probabilities = bigram_probabilities\n","    elif n == 3:\n","        ngram_probabilities = trigram_probabilities\n","    elif n == 4:\n","        ngram_probabilities = quadgram_probabilities\n","        \n","    sentence = [*seed_word]\n","\n","    next_words = [word[-1] for word in ngram_probabilities if word[:-1] == tuple(sentence[-(n-1):])]\n","\n","        \n","    return next_words[:5]"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"data":{"text/plain":["['ተገጥሞላቸው']"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["initial_sentence = \"ደቡብ መሮጫዎች\"\n","initial_sentence = tuple(initial_sentence.split())\n","\n","next_words = generate_next_words(initial_sentence, 2)\n","next_words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4024508,"sourceId":7000864,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
